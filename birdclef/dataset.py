# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_dataset.ipynb.

# %% auto 0
__all__ = ['dir', 'simple_classes', 'train_metadata_simple', 'val_metadata_simple', 'test_metadata_simple', 'dataset_dict',
           'MyPipeline', 'BirdClef', 'get_dataset', 'get_dataloader']

# %% ../nbs/02_dataset.ipynb 3
from IPython.display import Audio
import pandas as pd
from sklearn.preprocessing import LabelBinarizer

import torch
from torch.utils.data import Dataset, DataLoader
import torchaudio

from .utils import DATA_DIR, AUDIO_DATA_DIR, mel_to_wave, plot_audio, plot_spectrogram

# %% ../nbs/02_dataset.ipynb 6
# Define custom feature extraction pipeline.
#
# 1. Check for sample rate and resample
# 2. Waveform Augmenations
# 3. Convert to mel-scale
# 4. Mel Augmenations
# 5. Check for lenght and stretch shorter videos


class MyPipeline(torch.nn.Module):
    def __init__(
        self,
        c_length = 10,
        sample_rate=32000,
        f_min = 40,
        f_max = 15000,
        n_fft=2048,
        n_mels=128,
        hop_length = 512,
        power = 2.0
    ):
        super().__init__()

        self.c_length = c_length * 62.6 #626 sono 10 secondi
        self.sample_rate = sample_rate
        self.melspec = torchaudio.transforms.MelSpectrogram(sample_rate=self.sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, f_min=f_min, f_max=f_max, power=power)
        self.amptodb = torchaudio.transforms.AmplitudeToDB()
        self.stretch = torchaudio.transforms.TimeStretch(hop_length=hop_length, n_freq=128)

        #Augmentations
        # self.maskingFreq =  torchaudio.transforms.FrequencyMasking(freq_mask_param=30)
        # self.maskingTime = torchaudio.transforms.TimeMasking(time_mask_param=30)
        # self.noiser = torchaudio.transforms.AddNoise()
        # self.pitchShift = torchaudio.transforms.PitchShift(resample_freq, 4)


    def forward(self, filename):
        # 0 Load the File
        waveform, sample_rate = torchaudio.load(filename, frame_offset=0, num_frames=320000)
        
        # 1 Check for the sample rate and eventually resample to 32k
        if sample_rate != self.sample_rate:
           print("Wrong sample rate: resampling audio")
           resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=self.sample_rate)
           waveform = resampler(waveform)

        # # 2 Waveform Augmentation
        # #2.1 White noise
        # if random.randint(0,1) < 0.3:
        #   noise = torch.rand(1, 320000)
        #   noise = (noise - 0.5) * 0.2
        #   snr_dbs = torch.tensor([random.randint(2,8)])
        #   waveform = self.noiser(waveform, noise, snr_dbs)

        # # 2.2 Pitch Shift
        # if random.randint(0,1) < 1:
        # if True:
        #   waveform = self.pitchShift(waveform)


        # 3 Convert to mel-scale
        mel = self.melspec(waveform)
        mel = self.amptodb(mel)
        
        # 4 Mel Augmenations
        # 4.1 Frequency Masking
        # if True:
        #   mel = self.maskingFreq(mel)
        # # 4.2 Time Masking
        # if True:
        #   mel = self.maskingTime(mel)


        # 5 Check for the length and stretch it to 10s, it is a transformation used to regularize the length of the data
        if mel.shape[2] < self.c_length:
          print("Audio too short: stretching it.")
          replay_rate =  mel.shape[2]/self.c_length
          #print(f"replay rate {replay_rate}%")
          mel = self.stretch(mel, replay_rate)
          mel = mel[:,:,0:626]
          #print(f"stretched shape {stretched.shape}")

        return mel.float()

# %% ../nbs/02_dataset.ipynb 9
class BirdClef(Dataset):

    def __init__(self, metadata=None, classes=None):

        self.metadata = metadata
        self.classes = classes

        self.length = len(self.metadata)

        binarizer = LabelBinarizer()
        binarizer.fit(self.classes)

        self.labels = binarizer.transform(metadata.primary_label)

        # Initialize a pipeline
        self.pipeline = MyPipeline()
    
    def __len__(self):
        return self.length

    def __getitem__(self, idx):
        filename = AUDIO_DATA_DIR + self.metadata['filename'][idx]
        mel_spectrogram = self.pipeline(filename)

        label = self.labels[idx]
        label = torch.from_numpy(label).float()

        return mel_spectrogram, label

# %% ../nbs/02_dataset.ipynb 13
dir = DATA_DIR
try:
    train_metadata_base = pd.read_csv(dir + 'base/train_metadata.csv')
    val_metadata_base = pd.read_csv(dir + 'base/val_metadata.csv')
    test_metadata_base = pd.read_csv(dir + 'base/test_metadata.csv')
except FileNotFoundError:
    dir = 'data/'
    train_metadata_base = pd.read_csv(dir + 'base/train_metadata.csv')
    val_metadata_base = pd.read_csv(dir + 'base/val_metadata.csv')
    test_metadata_base = pd.read_csv(dir + 'base/test_metadata.csv')

simple_classes = ['thrnig1', 'wlwwar', 'barswa']
train_metadata_simple = train_metadata_base.loc[train_metadata_base.primary_label.isin(simple_classes)].reset_index()
val_metadata_simple = val_metadata_base.loc[val_metadata_base.primary_label.isin(simple_classes)].reset_index()
test_metadata_simple = test_metadata_base.loc[test_metadata_base.primary_label.isin(simple_classes)].reset_index()

# %% ../nbs/02_dataset.ipynb 14
dataset_dict = {
            'train_base': (BirdClef, {'metadata': train_metadata_base, 'classes': train_metadata_base.primary_label}),
            'val_base': (BirdClef, {'metadata': val_metadata_base, 'classes': train_metadata_base.primary_label}),
            'test_base': (BirdClef, {'metadata': test_metadata_base, 'classes': train_metadata_base.primary_label}),

            'train_simple': (BirdClef, {'metadata': train_metadata_simple, 'classes': train_metadata_simple.primary_label}),
            'val_simple': (BirdClef, {'metadata': val_metadata_simple, 'classes': train_metadata_simple.primary_label}),
            'test_simple': (BirdClef, {'metadata': test_metadata_simple, 'classes': train_metadata_simple.primary_label})
        }

# %% ../nbs/02_dataset.ipynb 15
def get_dataset(dataset_key:str        # A key of the dataset dictionary
                )->Dataset:         # Pytorch dataset
    "A getter method to retrieve the wanted dataset."
    assert dataset_key in dataset_dict, f'{dataset_key} is not an existing dataset, choose one from {dataset_dict.keys()}.'
    ds_class, kwargs = dataset_dict[dataset_key]
    return ds_class(**kwargs)

# %% ../nbs/02_dataset.ipynb 19
def get_dataloader(dataset_key:str,            # The key to access the dataset
                dataloader_kwargs:dict={}      # The optional parameters for a pytorch dataloader
                )->DataLoader:              # Pytorch dataloader
    "A function to get a dataloader from a specific dataset"
    dataset = get_dataset(dataset_key)

    return DataLoader(dataset, **dataloader_kwargs)
