{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment\n",
    "\n",
    "> Notebook where the training experiments take place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os\n",
    "if not os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    from nbdev.showdoc import *\n",
    "    from fastcore.test import *\n",
    "    from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT in Colab\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   print(\"Running in Colab\")       \n",
    "   from google.colab import drive\n",
    "   drive.mount('/content/drive')\n",
    "   %cd /content/drive/MyDrive/GitHub/birdclef_2023\n",
    "   %pip install wandb\n",
    "else:\n",
    "   print(\"NOT in Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import wandb\n",
    "\n",
    "from birdclef.trainer import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the variables that must be set to start an experiment:\n",
    "\n",
    "1. **project**: The name of the wandb project where the training, evaluation and test results will be logged and stored.\n",
    "\n",
    "2. **entity**: The wandb entity associated with the project.\n",
    "\n",
    "3. **sweep_name**: The name given to the sweep configuration, which defines the hyperparameter search setup for an experiment. It's used to organize and categorize different hyperparameter tuning runs.\n",
    "\n",
    "4. **method**: The method or strategy used for hyperparameter tuning. In this case, 'random' suggests that hyperparameters will be randomly chosen from the specified ranges or values during the sweep.\n",
    "\n",
    "5. **n_runs**: The number of runs or iterations that will be performed during the hyperparameter sweep. Each run involves training the model with a specific set of hyperparameters.\n",
    "\n",
    "6. **run_name**: The name given to each individual run or iteration of the experiment. It helps identify and differentiate between different runs, providing a meaningful label for tracking and analysis.\n",
    "\n",
    "7. **device**: The computational device (e.g., 'cpu', 'cuda') on which the training and evaluation of the model will be performed.\n",
    "\n",
    "8. **train_key**: Key or identifier used to access the training dataset. Refer to `get_dataset` for info about available keys.\n",
    "\n",
    "9. **val_key**: Key or identifier used to access the validation dataset. Refer to `get_dataset` for info about available keys.\n",
    "\n",
    "10. **test_key**: Key or identifier used to access the test dataset. Refer to `get_dataset` for info about available keys.\n",
    "\n",
    "11. **batch_size**: The number of samples in each mini-batch during training. It affects the efficiency of the training process and the model's ability to generalize.\n",
    "\n",
    "12. **num_workers**: The number of worker threads used to load data in parallel during training. It can help speed up the data loading process.\n",
    "\n",
    "13. **pin_memory**: A boolean indicating whether to pin memory for faster data transfer to the GPU. This is often beneficial when using a GPU for training.\n",
    "\n",
    "14. **model_key**: Key or identifier used to specify the model architecture to be used for training. Refer to `get_model` for info about available keys.\n",
    "\n",
    "15. **optimizer_key**: Key or identifier used to specify the optimizer to be used during the training process. Refer to `get_optimizer` for info about available keys.\n",
    "\n",
    "16. **learning_rate**: A list of learning rates to be used by the optimizer during training. Learning rate is a crucial hyperparameter affecting the convergence and performance of the model.\n",
    "\n",
    "17. **loss_key**: Key or identifier used to specify the loss function to be used during training. Refer to `get_loss_func` for info about available keys.\n",
    "\n",
    "18. **metric**: The metric used to evaluate the model's performance. This metric is used to compare and choose the best model in a single run. Refer to `compute_metrics` for info about available metrics.\n",
    "\n",
    "19. **epochs**: The number of epochs or complete passes through the training dataset during the training process. One epoch is a single pass through the entire training dataset.\n",
    "\n",
    "20. **callback_step**: A callback function will be called every *n* steps where *n* is the number defined as *callback_step*\n",
    "\n",
    "21. **callback_func**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The existing keys are:\n",
    "- train_base\n",
    "- val_base\n",
    "- test_base\n",
    "- train_simple\n",
    "- val_simple\n",
    "- test_simple\n",
    "- train_simple_per_channel\n",
    "- val_simple_per_channel\n",
    "- test_simple_per_channel\n",
    "- train_base_per_channel\n",
    "- val_base_per_channel\n",
    "- test_base_per_channel\n",
    "- train_base_pcn_aug\n",
    "- val_base_pcn_aug\n",
    "- test_base_pcn_aug\n",
    "- train_base_pcn_rnd\n",
    "- val_base_pcn_rnd\n",
    "- test_base_pcn_rnd\n",
    "- train_base_pcn_aug_rnd\n",
    "- val_base_pcn_aug_rnd\n",
    "- test_base_pcn_aug_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'bird-clef-cjavelanda'\n",
    "entity = '4projects'\n",
    "\n",
    "sweep_name = 'sweep-per_channel' \n",
    "method = 'random'\n",
    "n_runs = 1\n",
    "run_name = 'per_channel_linear_0005' \n",
    "device = 'cuda' \n",
    "train_key = 'train_base_per_channel'\n",
    "val_key = 'val_base_per_channel' \n",
    "test_key = 'test_base_per_channel'\n",
    "batch_size = 128\n",
    "num_workers = 16\n",
    "pin_memory = True\n",
    "model_key = 'efficient_net_v2_s' \n",
    "optimizer_key = 'adamw' \n",
    "learning_rate = [0.0005] \n",
    "loss_key = 'ce'\n",
    "metric = 'f1'\n",
    "epochs = 11\n",
    "callback_step = 100\n",
    "callback_key = 'show'\n",
    "scheduler_key = 'linear'\n",
    "scheduler_metric = 'loss'\n",
    "scheduler_step = 2\n",
    "start_factor = 1\n",
    "end_factor = 1e-6\n",
    "scheduler_verbose = 1\n",
    "scheduler_patience = 5\n",
    "scheduler_eta_min = 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the experiment configuration as dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'name': sweep_name,\n",
    "    'method': method,\n",
    "    'parameters': {\n",
    "        'run_name': {\n",
    "            'value': run_name\n",
    "        },\n",
    "        'device': {\n",
    "            'value': device\n",
    "        },\n",
    "        'train_key': {\n",
    "            'value': train_key\n",
    "        },\n",
    "        'train_kwargs': {\n",
    "            'parameters': {\n",
    "                'batch_size': {\n",
    "                    'value': batch_size\n",
    "                },\n",
    "                'shuffle': {\n",
    "                    'value': True\n",
    "                },\n",
    "                'num_workers': {\n",
    "                    'value': num_workers \n",
    "                },\n",
    "                'pin_memory': {\n",
    "                    'value': pin_memory\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'val_key': {\n",
    "            'value': val_key\n",
    "        },\n",
    "        'test_key': {\n",
    "            'value': test_key\n",
    "        },\n",
    "        'val_kwargs': {\n",
    "            'parameters': {\n",
    "                'batch_size': {\n",
    "                    'value': batch_size\n",
    "                },\n",
    "                'shuffle': {\n",
    "                    'value': False\n",
    "                },\n",
    "                'num_workers': {\n",
    "                    'value': num_workers \n",
    "                },\n",
    "                'pin_memory': {\n",
    "                    'value': pin_memory\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'model_key': {\n",
    "            'value': model_key\n",
    "        },\n",
    "        'optimizer_key': {\n",
    "            'value': optimizer_key\n",
    "        },\n",
    "        'optimizer_kwargs': {\n",
    "            'parameters': {\n",
    "                'lr': {\n",
    "                    'values': learning_rate\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        'loss_key': {\n",
    "            'value': loss_key\n",
    "        },\n",
    "        'metric': {\n",
    "            'value': metric\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': epochs\n",
    "        },\n",
    "        'callback_step': {\n",
    "            'value': callback_step\n",
    "        },\n",
    "        'callback_key': {\n",
    "            'value': callback_key\n",
    "        },\n",
    "        'lr_scheduler_key' : {\n",
    "            'value' : scheduler_key\n",
    "        },\n",
    "        'lr_scheduler_kwargs' : {\n",
    "            'parameters' : {\n",
    "                'start_factor' : {\n",
    "                    'value' : start_factor\n",
    "                },\n",
    "                'end_factor' : {\n",
    "                    'value' : end_factor\n",
    "                },\n",
    "                'verbose' : {\n",
    "                    'value' : scheduler_verbose\n",
    "                },\n",
    "                'patience' : {\n",
    "                    'value' : scheduler_patience\n",
    "                },\n",
    "                'scheduler_step' : {\n",
    "                    'value' : scheduler_step\n",
    "                },\n",
    "                'scheduler_metric' : {\n",
    "                    'value' : scheduler_metric\n",
    "                },\n",
    "                'eta_min' : {\n",
    "                    'value' : scheduler_eta_min\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Need to change wd when running in colab\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "  %cd /content/drive/MyDrive/GitHub/birdclef_2023/nbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 8mo1tqm5\n",
      "Sweep URL: https://wandb.ai/4projects/bird-clef-cjavelanda/sweeps/8mo1tqm5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cqw7h9b6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcallback_key: show\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcallback_step: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdevice: cuda\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_key: ce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_key: linear\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_kwargs: {'end_factor': 1e-06, 'eta_min': 1e-09, 'patience': 5, 'scheduler_metric': 'loss', 'scheduler_step': 2, 'start_factor': 1, 'verbose': 1}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmetric: f1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_key: efficient_net_v2_s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_key: adamw\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_kwargs: {'lr': 0.0005}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trun_name: per_channel_linear_0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttest_key: test_base_per_channel\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_key: train_base_per_channel\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_kwargs: {'batch_size': 128, 'num_workers': 16, 'pin_memory': True, 'shuffle': True}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_key: val_base_per_channel\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_kwargs: {'batch_size': 128, 'num_workers': 16, 'pin_memory': True, 'shuffle': False}\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteorossireich\u001b[0m (\u001b[33m4projects\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>h:\\Birds\\birdclef_2023\\nbs\\wandb\\run-20231126_131707-cqw7h9b6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4projects/bird-clef-cjavelanda/runs/cqw7h9b6' target=\"_blank\">deep-sweep-1</a></strong> to <a href='https://wandb.ai/4projects/bird-clef-cjavelanda' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/4projects/bird-clef-cjavelanda/sweeps/8mo1tqm5' target=\"_blank\">https://wandb.ai/4projects/bird-clef-cjavelanda/sweeps/8mo1tqm5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4projects/bird-clef-cjavelanda' target=\"_blank\">https://wandb.ai/4projects/bird-clef-cjavelanda</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/4projects/bird-clef-cjavelanda/sweeps/8mo1tqm5' target=\"_blank\">https://wandb.ai/4projects/bird-clef-cjavelanda/sweeps/8mo1tqm5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4projects/bird-clef-cjavelanda/runs/cqw7h9b6' target=\"_blank\">https://wandb.ai/4projects/bird-clef-cjavelanda/runs/cqw7h9b6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/78 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"h:\\birds\\birdclef_2023\\birdclef\\trainer.py\", line 174, in train\n",
      "    metrics, example_ct, step_ct = train_one_epoch(model, train_dl, loss_func, optimizer, config.device, epoch, example_ct, step_ct, n_steps_per_epoch, config.callback_step, callback_func, config.lr_scheduler_kwargs[\"scheduler_step\"], config.lr_scheduler_kwargs[\"scheduler_metric\"], lr_scheduler)\n",
      "  File \"h:\\birds\\birdclef_2023\\birdclef\\trainer.py\", line 56, in train_one_epoch\n",
      "    for step, data in enumerate(train_dl):\n",
      "  File \"h:\\Birds\\birdclef_2023\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"h:\\Birds\\birdclef_2023\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1345, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"h:\\Birds\\birdclef_2023\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1371, in _process_data\n",
      "    data.reraise()\n",
      "  File \"h:\\Birds\\birdclef_2023\\.venv\\lib\\site-packages\\torch\\_utils.py\", line 694, in reraise\n",
      "    raise exception\n",
      "soundfile.LibsndfileError: <exception str() failed>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-sweep-1</strong> at: <a href='https://wandb.ai/4projects/bird-clef-cjavelanda/runs/cqw7h9b6' target=\"_blank\">https://wandb.ai/4projects/bird-clef-cjavelanda/runs/cqw7h9b6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231126_131707-cqw7h9b6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run cqw7h9b6 errored: LibsndfileError('Caught LibsndfileError in DataLoader worker process 0.\\nOriginal Traceback (most recent call last):\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\utils\\\\data\\\\_utils\\\\worker.py\", line 308, in _worker_loop\\n    data = fetcher.fetch(index)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\utils\\\\data\\\\_utils\\\\fetch.py\", line 51, in fetch\\n    data = [self.dataset[idx] for idx in possibly_batched_index]\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\utils\\\\data\\\\_utils\\\\fetch.py\", line 51, in <listcomp>\\n    data = [self.dataset[idx] for idx in possibly_batched_index]\\n  File \"h:\\\\birds\\\\birdclef_2023\\\\birdclef\\\\dataset.py\", line 163, in __getitem__\\n    mel_spectrogram = self.pipeline(filename)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\nn\\\\modules\\\\module.py\", line 1518, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\nn\\\\modules\\\\module.py\", line 1527, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"h:\\\\birds\\\\birdclef_2023\\\\birdclef\\\\dataset.py\", line 72, in forward\\n    waveform, sample_rate = torchaudio.load(filename, frame_offset=0, num_frames=self.seconds*self.sample_rate)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torchaudio\\\\_backend\\\\utils.py\", line 204, in load\\n    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torchaudio\\\\_backend\\\\soundfile.py\", line 27, in load\\n    return soundfile_backend.load(uri, frame_offset, num_frames, normalize, channels_first, format)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torchaudio\\\\_backend\\\\soundfile_backend.py\", line 221, in load\\n    with soundfile.SoundFile(filepath, \"r\") as file_:\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\soundfile.py\", line 658, in __init__\\n    self._file = self._open(file, mode_int, closefd)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\soundfile.py\", line 1216, in _open\\n    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\\nsoundfile.LibsndfileError: Error opening \\'../data/audio_data/wlwwar/XC653187.ogg\\': System error.\\n', '')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run cqw7h9b6 errored: LibsndfileError('Caught LibsndfileError in DataLoader worker process 0.\\nOriginal Traceback (most recent call last):\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\utils\\\\data\\\\_utils\\\\worker.py\", line 308, in _worker_loop\\n    data = fetcher.fetch(index)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\utils\\\\data\\\\_utils\\\\fetch.py\", line 51, in fetch\\n    data = [self.dataset[idx] for idx in possibly_batched_index]\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\utils\\\\data\\\\_utils\\\\fetch.py\", line 51, in <listcomp>\\n    data = [self.dataset[idx] for idx in possibly_batched_index]\\n  File \"h:\\\\birds\\\\birdclef_2023\\\\birdclef\\\\dataset.py\", line 163, in __getitem__\\n    mel_spectrogram = self.pipeline(filename)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\nn\\\\modules\\\\module.py\", line 1518, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torch\\\\nn\\\\modules\\\\module.py\", line 1527, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"h:\\\\birds\\\\birdclef_2023\\\\birdclef\\\\dataset.py\", line 72, in forward\\n    waveform, sample_rate = torchaudio.load(filename, frame_offset=0, num_frames=self.seconds*self.sample_rate)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torchaudio\\\\_backend\\\\utils.py\", line 204, in load\\n    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torchaudio\\\\_backend\\\\soundfile.py\", line 27, in load\\n    return soundfile_backend.load(uri, frame_offset, num_frames, normalize, channels_first, format)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\torchaudio\\\\_backend\\\\soundfile_backend.py\", line 221, in load\\n    with soundfile.SoundFile(filepath, \"r\") as file_:\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\soundfile.py\", line 658, in __init__\\n    self._file = self._open(file, mode_int, closefd)\\n  File \"h:\\\\Birds\\\\birdclef_2023\\\\.venv\\\\lib\\\\site-packages\\\\soundfile.py\", line 1216, in _open\\n    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\\nsoundfile.LibsndfileError: Error opening \\'../data/audio_data/wlwwar/XC653187.ogg\\': System error.\\n', '')\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "#|output: false\n",
    "sweep_id = wandb.sweep(sweep_config, project=project, entity=entity)\n",
    "wandb.agent(\n",
    "    sweep_id,\n",
    "    train,\n",
    "    count=n_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if not os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
