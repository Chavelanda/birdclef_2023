{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment\n",
    "\n",
    "> Notebook where the training experiments take place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import wandb\n",
    "\n",
    "from dm_4_cat.trainer import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the variables that must be set to start an experiment:\n",
    "\n",
    "1. **project**: The name of the wandb project where the training, evaluation and test results will be logged and stored.\n",
    "\n",
    "2. **entity**: The wandb entity associated with the project.\n",
    "\n",
    "3. **sweep_name**: The name given to the sweep configuration, which defines the hyperparameter search setup for an experiment. It's used to organize and categorize different hyperparameter tuning runs.\n",
    "\n",
    "4. **method**: The method or strategy used for hyperparameter tuning. In this case, 'random' suggests that hyperparameters will be randomly chosen from the specified ranges or values during the sweep.\n",
    "\n",
    "5. **n_runs**: The number of runs or iterations that will be performed during the hyperparameter sweep. Each run involves training the model with a specific set of hyperparameters.\n",
    "\n",
    "6. **run_name**: The name given to each individual run or iteration of the experiment. It helps identify and differentiate between different runs, providing a meaningful label for tracking and analysis.\n",
    "\n",
    "7. **device**: The computational device (e.g., 'cpu', 'cuda') on which the training and evaluation of the model will be performed.\n",
    "\n",
    "8. **train_key**: Key or identifier used to access the training dataset. Refer to `get_dataset` for info about available keys.\n",
    "\n",
    "9. **val_key**: Key or identifier used to access the validation dataset. Refer to `get_dataset` for info about available keys.\n",
    "\n",
    "10. **test_key**: Key or identifier used to access the test dataset. Refer to `get_dataset` for info about available keys.\n",
    "\n",
    "11. **batch_size**: The number of samples in each mini-batch during training. It affects the efficiency of the training process and the model's ability to generalize.\n",
    "\n",
    "12. **num_workers**: The number of worker threads used to load data in parallel during training. It can help speed up the data loading process.\n",
    "\n",
    "13. **pin_memory**: A boolean indicating whether to pin memory for faster data transfer to the GPU. This is often beneficial when using a GPU for training.\n",
    "\n",
    "14. **model_key**: Key or identifier used to specify the model architecture to be used for training. Refer to `get_model` for info about available keys.\n",
    "\n",
    "15. **optimizer_key**: Key or identifier used to specify the optimizer to be used during the training process. Refer to `get_optimizer` for info about available keys.\n",
    "\n",
    "16. **learning_rate**: A list of learning rates to be used by the optimizer during training. Learning rate is a crucial hyperparameter affecting the convergence and performance of the model.\n",
    "\n",
    "17. **loss_key**: Key or identifier used to specify the loss function to be used during training. Refer to `get_loss_func` for info about available keys.\n",
    "\n",
    "18. **metric**: The metric used to evaluate the model's performance. This metric is used to compare and choose the best model in a single run. Refer to `compute_metrics` for info about available metrics.\n",
    "\n",
    "19. **epochs**: The number of epochs or complete passes through the training dataset during the training process. One epoch is a single pass through the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = ''\n",
    "entity = ''\n",
    "\n",
    "sweep_name = 'test' \n",
    "method = 'random'\n",
    "n_runs = 1\n",
    "\n",
    "run_name = 'test' \n",
    "device = 'cpu' \n",
    "train_key = '' \n",
    "val_key = '' \n",
    "test_key = '' \n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "pin_memory = True\n",
    "model_key = '' \n",
    "optimizer_key = '' \n",
    "learning_rate = [0.0001] \n",
    "loss_key = ''\n",
    "metric = ''\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the experiment configuration as dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'name': sweep_name,\n",
    "    'method': method,\n",
    "    'parameters': {\n",
    "        'run_name': {\n",
    "            'value': run_name\n",
    "        },\n",
    "        'device': {\n",
    "            'value': device\n",
    "        },\n",
    "        'train_key': {\n",
    "            'value': train_key\n",
    "        },\n",
    "        'train_kwargs': {\n",
    "            'parameters': {\n",
    "                'batch_size': {\n",
    "                    'value': batch_size\n",
    "                },\n",
    "                'shuffle': {\n",
    "                    'value': True\n",
    "                },\n",
    "                'num_workers': {\n",
    "                    'value': num_workers \n",
    "                },\n",
    "                'pin_memory': {\n",
    "                    'value': pin_memory\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'val_key': {\n",
    "            'value': val_key\n",
    "        },\n",
    "        'test_key': {\n",
    "            'value': test_key\n",
    "        },\n",
    "        'val_kwargs': {\n",
    "            'parameters': {\n",
    "                'batch_size': {\n",
    "                    'value': batch_size\n",
    "                },\n",
    "                'shuffle': {\n",
    "                    'value': False\n",
    "                },\n",
    "                'num_workers': {\n",
    "                    'value': num_workers \n",
    "                },\n",
    "                'pin_memory': {\n",
    "                    'value': pin_memory\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'model_key': {\n",
    "            'value': model_key\n",
    "        },\n",
    "        'model_kwargs': {\n",
    "            'parameters': {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "        'optimizer_key': {\n",
    "            'value': optimizer_key\n",
    "        },\n",
    "        'optimizer_kwargs': {\n",
    "            'parameters': {\n",
    "                'learning_rate': {\n",
    "                    'values': learning_rate\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        'loss_key': {\n",
    "            'value': loss_key\n",
    "        },\n",
    "        'metric': {\n",
    "            'value': metric\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': epochs\n",
    "        }\n",
    "    }  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "sweep_id = wandb.sweep(sweep_config, project=project, entity=entity)\n",
    "wandb.agent(\n",
    "    sweep_id,\n",
    "    train,\n",
    "    count=n_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
